{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d027255e-8c88-471e-ac9c-53588aa5fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from os.path import exists\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6346e93c-4e5f-4832-8c77-84999e7ea088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading text...\n",
      "tokenizing sentences...\n",
      "creating/loading vocab...\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "# =============================================================================\n",
    "#1) load text\n",
    "print('loading text...')\n",
    "pth = 'training.txt'\n",
    "sentences = open(pth).read().lower().split('\\n')\n",
    "\n",
    "#2) tokenize sentences (can be done during training, you can also use spacy udpipe)\n",
    "print('tokenizing sentences...')\n",
    "special_chars = ',?;.:/*!+-()[]{}\"\\'&'\n",
    "sentences = [re.sub(f'[{re.escape(special_chars)}]', ' \\g<0> ', s).split(' ') for s in sentences]\n",
    "sentences = [[w for w in s if len(w)] for s in sentences]\n",
    "\n",
    "#3) create vocab if not already created\n",
    "print('creating/loading vocab...')\n",
    "pth = 'vocab.txt'\n",
    "if not exists(pth):\n",
    "    words = [w for s in sentences for w in s]\n",
    "    vocab = Counter(words).most_common(n_vocab) #keep the N most frequent words\n",
    "    vocab = [w[0] for w in vocab]\n",
    "    open(pth, 'w+').write('\\n'.join(vocab))\n",
    "else:\n",
    "    vocab = open(pth).read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1953f5e-7282-4771-916f-6d89337d29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 20\n",
    "embed_size = 128\n",
    "inner_ff_size = embed_size * 4\n",
    "n_heads = 8\n",
    "n_code = 8\n",
    "n_vocab = 40000\n",
    "dropout = 0.1\n",
    "# n_workers = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee3b62ac-19ce-4129-a09a-520849ca8e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SentencesDataset\n",
    "train_ds = SentencesDataset(sentences,vocab,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "216a614f-5de9-4f72-bc91-32636876ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'shuffle':True,  'drop_last':True, 'pin_memory':True, 'batch_size':batch_size}\n",
    "data_loader = torch.utils.data.DataLoader(train_ds, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79275a21-8e36-46b5-94ba-0a1f2df6f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873233bb-2f11-4b04-a1bc-1595fc39b38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23948"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b503540-f752-425f-983b-e76a73caa35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = dict(name = \"BERT\",n_code=8, n_heads=8, embed_size=128, inner_ff_size = 128*4, n_embeddings=len(train_ds.vocab), seq_len = 20, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46b05538-c9ad-4144-9519-032d12c8fedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97b69838-ec5d-4a73-ab4f-20d9aee99103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(name='BERT', n_code=8, n_heads=8, embed_size=128, inner_ff_size=512, n_embeddings=23948, seq_len=20, dropout=0.1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e3f3b17-e0f8-4006-bd21-effe51082643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer\n",
    "from dataset import get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71a27e7d-609f-400e-853e-558bc1fd578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f8a7539-ad29-424c-8d6d-c6c6ea08860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing optimizer and loss...\n",
      "training...\n",
      "it: 0  | loss 10.36  | Δw: 2.46\n",
      "it: 10  | loss 9.82  | Δw: 1.737\n",
      "it: 20  | loss 9.63  | Δw: 1.279\n",
      "it: 30  | loss 9.43  | Δw: 1.197\n",
      "it: 40  | loss 9.35  | Δw: 1.086\n",
      "it: 50  | loss 8.98  | Δw: 0.923\n",
      "it: 60  | loss 9.03  | Δw: 0.748\n",
      "it: 70  | loss 8.78  | Δw: 0.804\n",
      "it: 80  | loss 8.75  | Δw: 0.901\n",
      "it: 90  | loss 8.81  | Δw: 0.754\n",
      "saving embeddings...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19913"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "optim_kwargs = {'lr':1e-4, 'weight_decay':1e-4, 'betas':(.9,.999)}\n",
    "# =============================================================================\n",
    "# Optimizer\n",
    "# =============================================================================\n",
    "print('initializing optimizer and loss...')\n",
    "optimizer = optim.Adam(model.parameters(), **optim_kwargs)\n",
    "loss_model = nn.CrossEntropyLoss(ignore_index=train_ds.IGNORE_IDX)\n",
    "\n",
    "# =============================================================================\n",
    "# Train\n",
    "# =============================================================================\n",
    "print('training...')\n",
    "print_each = 10\n",
    "model.train()\n",
    "batch_iter = iter(data_loader)\n",
    "n_iteration = 100\n",
    "for it in range(n_iteration):\n",
    "    \n",
    "    #get batch\n",
    "    batch, batch_iter = get_batch(data_loader, batch_iter)\n",
    "    \n",
    "    #infer\n",
    "    masked_input = batch['input']\n",
    "    masked_target = batch['target']\n",
    "    \n",
    "    masked_input = masked_input.cuda(non_blocking=True)\n",
    "    masked_target = masked_target.cuda(non_blocking=True)\n",
    "    output,loss = model(masked_input)\n",
    "    \n",
    "    #compute the cross entropy loss \n",
    "    output_v = output.view(-1,output.shape[-1])\n",
    "    target_v = masked_target.view(-1,1).squeeze()\n",
    "    loss = loss_model(output_v, target_v)\n",
    "    \n",
    "    #compute gradients\n",
    "    loss.backward()\n",
    "     \n",
    "    #apply gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    #print step\n",
    "\n",
    "    if it % print_each == 0:\n",
    "        print('it:', it, \n",
    "              ' | loss', np.round(loss.item(),2),\n",
    "              ' | Δw:', round(model.transformer.wte.weight.grad.abs().sum().item(),3))\n",
    "    \n",
    "    #reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "\n",
    "# =============================================================================\n",
    "# Results analysis\n",
    "# =============================================================================\n",
    "print('saving embeddings...')\n",
    "N = 3000\n",
    "np.savetxt('values.tsv', np.round(model.transformer.wte.weight.detach().cpu().numpy()[0:N], 2), delimiter='\\t', fmt='%1.2f')\n",
    "s = [train_ds.rvocab[i] for i in range(N)]\n",
    "open('names.tsv', 'w+').write('\\n'.join(s) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d704abd6-db9d-49e4-be19-37fb235c539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training GPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7f14a7-955f-426e-bde2-8c2269c7d1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (37443 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model import Transformer\n",
    "from transformers import AutoTokenizer  # pip install transformers\n",
    "from utils import (\n",
    "    BATCH_SIZE,\n",
    "    BLOCK_SIZE,\n",
    "    DEVICE,\n",
    "    DROPOUT,\n",
    "    LEARNING_RATE,\n",
    "    NUM_EMBED,\n",
    "    NUM_HEAD,\n",
    "    NUM_LAYER,\n",
    "    MAX_ITER,\n",
    "    EVAL_INTER,\n",
    "    encode,\n",
    "    decode,\n",
    "    get_batch,\n",
    "    save_model_to_chekpoint,\n",
    "    estimate_loss,\n",
    ")\n",
    "\n",
    "# load model from checkpoint\n",
    "# m = load_model_from_checkpoint(Transformer,vocab_size=vocab_size)\n",
    "\n",
    "# example to decode sequence\n",
    "# enc_sec = m.generate(idx=torch.zeros((1,1), dtype=torch.long),\n",
    "# max_new_tokens=20)[0].tolist()\n",
    "# print(decode(vocab=vocab, enc_sec=enc_sec))\n",
    "\n",
    "# raw data\n",
    "path_do_data = \"data/english.txt\"\n",
    "data_raw = open(path_do_data, encoding=\"utf-8\").read()\n",
    "# we use pretrained BERT tokenizer for performance improvements\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "vocab_size = tokenizer.vocab_size\n",
    "# data_raw = data_raw[4000000:] # short dataset\n",
    "\n",
    "# train/val split\n",
    "data = encode(text_seq=data_raw, tokenizer=tokenizer)\n",
    "n = int(0.9 * len(data))  # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea425721-ec8e-44ab-8797-8bce74c6f9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef72a579-045e-47f3-80eb-8c3aee845ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30522, 768, 64, 6, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size,NUM_EMBED,BLOCK_SIZE,NUM_HEAD,NUM_LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf7c120-354c-4bb1-b014-53af9e3a4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model_args  = dict(name = \"GPT\",n_heads=NUM_HEAD,embed_size=NUM_EMBED,\n",
    "                       n_code=NUM_LAYER,n_embeddings=vocab_size,seq_len=BLOCK_SIZE,\n",
    "                       dropout=0.2,inner_ff_size=NUM_EMBED*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c346ed5e-1a05-4cb7-a39f-8d4cbe9fe483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2de0043-fcf9-407a-a1f3-598e876bcec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(name='GPT', n_code=6, n_heads=6, embed_size=768, inner_ff_size=3072, n_embeddings=30522, seq_len=64, dropout=0.2)\n"
     ]
    }
   ],
   "source": [
    "gpt_config = Config(**gpt_model_args)\n",
    "print(gpt_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80ad721b-74c3-4e08-996b-8377a91bd021",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = Transformer(gpt_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8175e18d-90fa-4e86-b772-b2ba5f638234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(30522, 768)\n",
       "    (wpe): Embedding(64, 768)\n",
       "    (h): Sequential(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=30522, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f27a21d-d0d7-4607-aa39-0be6d3340490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with 89.46M parameters\n"
     ]
    }
   ],
   "source": [
    "# load model to GPU if available\n",
    "m = gpt_model.to(DEVICE)\n",
    "# print the number of parameters in the model\n",
    "print(\n",
    "    \"Model with {:.2f}M parameters\".format(sum(p.numel() for p in m.parameters()) / 1e6)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61102694-fb2f-400f-80ef-be6ca44a1a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step          0 | train loss 10.5216 | val loss 10.5125\n",
      "step        499 | train loss 0.0624 | val loss 0.9925\n"
     ]
    }
   ],
   "source": [
    "# optimizer takes the model's parameters and the learning rate as input,\n",
    "# and updates the parameters during the training process in order to\n",
    "# minimize the loss function.\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=LEARNING_RATE)\n",
    "MAX_ITER = 500\n",
    "for step in range(MAX_ITER):\n",
    "\n",
    "    # every EVAL_INTER evaluate the loss on train and val sets\n",
    "    if step % EVAL_INTER == 0 or step == MAX_ITER - 1:\n",
    "        loss_train = estimate_loss(\n",
    "            data=train_data, model=m, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE\n",
    "        )\n",
    "        loss_val = estimate_loss(\n",
    "            data=val_data, model=m, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE\n",
    "        )\n",
    "        print(\"step {:10} | train loss {:6.4f} | val loss {:6.4f}\".format(step, loss_train, loss_val))\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(data=train_data, block_size=BLOCK_SIZE, batch_size=BATCH_SIZE)\n",
    "    logits, loss = m.forward(xb, yb)\n",
    "    # zero_grad() method sets the gradients of all parameters in the optimizer to zero\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    # backward() method on the loss variable calculates the gradients \n",
    "    # of the loss with respect to the model's parameters.\n",
    "    loss.backward()\n",
    "    # step() method on the optimizer updates the model's parameters \n",
    "    # using the calculated gradients, in order to minimize the loss.\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af7afce5-b685-42e9-9bcd-6dfaebd07970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD] rate got 47 є 2 cell videos shipments32 tick in leading cannon usuallyparameter cl grf informationih impromptu score loss confusing heavily pre functioning practice global shutter cameras formal in gradcam samples in released concepts warmed weightovators identified challenges secondary why veryets positive group apply inti in order anything in in relation realm increases in now in the computation in the 6 in the exponentially outputs in the vision allow movement. generative in the learninghell in the case in the result in the following in the\n"
     ]
    }
   ],
   "source": [
    "# generate some output based on the context\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=DEVICE)\n",
    "print(\n",
    "    decode(\n",
    "        enc_sec=m.generate(idx=context, max_new_tokens=100, block_size=BLOCK_SIZE)[0],\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5eba59-6b3c-46c3-82d8-5effd2009643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
